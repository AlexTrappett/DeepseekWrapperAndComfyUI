Requires Ollama to be running: 
  "Ollama serve"
Deepseek model: DeepSeek-R1-0528-Qwen3-8B: 
  "ollama run deepseek-r1"
  https://ollama.com/library/deepseek-r1
Ollama runs on: "http://localhost:11434"
